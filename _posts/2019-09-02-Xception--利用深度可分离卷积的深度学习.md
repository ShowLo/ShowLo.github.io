---
layout:     post
title:      Xception--利用深度可分离卷积的深度学习
subtitle:   Xception--Deep Learning with Depthwise Separable Convolutions
date:       2019-09-02
author:     CJR
header-img: img/2019-09-02-Xception--利用深度可分离卷积的深度学习/post-bg.jpg
catalog: true
mathjax: true
tags:
    - Lightweight Network
    - Xception
    - Depthwise Separable Convolutions
    - CNN
---

## Xception

&emsp;之前介绍MobileNet的时候说过深度可分离卷积，不过说起来这篇Xception的论文还要更早利用/借鉴到深度可分离卷积（当然两者都不是原创，而是借鉴了2014年的一篇博士论文：《L. Sifre. Rigid-motion scattering for image classification. hD thesis, Ph. D. thesis, 2014》），该文章发表在了CVPR 2017上，原文可见[Xception: Deep Learning with Depthwise Separable Convolutions](https://arxiv.org/abs/1610.02357)。

---

## 摘要

&emsp;我们将卷积神经网络中的Inception模块解释为普通卷积和深度可分离卷积操作（深度卷积后接逐点卷积）之间的中间状态。从这个意义上讲，深度可分离卷积可以理解为一个具有最大数量tower的Inception模块。基于此，我们提出了一种新颖的深度卷积神经网络结构，该结构受到Inception的启发，Inception模块被深度可分离卷积所取代。我们展示了这个被称为Xception的架构，它在ImageNet数据集上稍微优于Inception V3 （Inception V3是为ImageNet数据集设计的），并且在一个包含3.5亿张图像和17000个类的更大的图像分类数据集上显著优于Inception V3。由于Xception体系结构具有与Inception V3相同的参数数量，所以性能的提高不是由于容量的增加，而是由于更有效地使用了模型参数。

## 1. 引言

&emsp;卷积神经网络是近年来计算机视觉领域中出现的一种主要算法，开发卷积神经网络的设计方法一直是一个备受关注的课题。卷积神经网络设计的历史始于LeNet风格的模型，它是用于特征提取的卷积和空间下采样的最大池化操作的简单堆栈。2012年，这些想法被提炼成AlexNet架构，其中卷积操作在最大池化操作之间重复多次，允许网络在每个空间尺度上学习更丰富的特征。随之而来的是一种趋势，使这种类型的网络越来越深，主要是由每年的ILSVRC竞赛推动；首先是2013年的Zeiler和Fergus，然后是2014年的VGG架构。

&emsp;此时，出现了一种新的网络风格，即Inception架构，由Szegedy等人于2014年以GoogLeNet（Inception V1）的形式引入，后来改进为Inception V2、Inception V3，以及最近的Inception-Resnet。 Inception本身受到了更早的Network-In-Network的启发。自首次引入以来，Inception一直是ImageNet数据集上（以及谷歌上使用的内部数据集，特别是JFT）性能最好的模型家族之一。

&emsp;Inception风格的模型的基本构建块是Inception模块，其中有几个不同的版本。在图1中，我们展示了Inception模块的规范形式，正如在Inception V3架构中所发现的那样。一个Inception模型可以理解为这些模块的堆栈。这与早期的VGG风格的网络不同，后者是由简单的卷积层堆积而成。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-09-02-Xception--利用深度可分离卷积的深度学习/figure1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图1. 规范的Inception模块（Inception V3）</div>
</center>

&emsp;虽然Inception模块在概念上类似于卷积（它们是卷积特征提取器），但从经验上看，它们似乎能够用更少的参数学习更丰富的表示。它们是如何工作的，它们与普通卷积有什么不同？什么样的设计策略在Inception后出现？

### 1.1 Inception假设

&emsp;卷积层尝试在具有2个空间维度（宽、高）和通道维度的三维空间中学习滤波器；因此，单个卷积核的任务是同时映射跨通道相关性和空间相关性。

&emsp;Inception模块背后的想法是通过显式地将其分解为一系列独立地查看跨通道相关性和空间相关性的操作，从而使这个过程更加简单和高效。更准确地说，典型的Inception模块首先通过一组$1\times 1$卷积来查看跨通道相关性，将输入数据映射到比原始输入空间小的3或4个单独的空间中，然后通过常规$3\times 3$或$5\times 5$卷积映射这些较小的3D空间中的所有相关性。如图1所示。实际上，Inception背后的基本假设是，跨通道相关性和空间相关性已充分解耦，因此最好不要联合映射它们。

&emsp;考虑一个简化版的Inception模块，只使用一个尺寸的卷积（例如$3\times 3$）且不包括平均池化tower（图2）。这个Inception模块可以重新设计为一个大的$1\times 1$卷积，然后再进行空间卷积，这些空间卷积将在输出通道的非重叠段上运行（图3）。这一观察自然提出了一个问题：分区中的段数（及其大小）有什么影响？是否有理由提出比Inception假设更强有力的假设，并假设跨通道相关性和空间相关性可以完全分开映射？

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-09-02-Xception--利用深度可分离卷积的深度学习/figure2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图2. 简化的Inception模块</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-09-02-Xception--利用深度可分离卷积的深度学习/figure3.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图3. 一个严格等价的简化的Inception模块的重新构造</div>
</center>

### 1.2 卷积与可分离卷积之间的连续性

&emsp;Inception模块的“极端”版本，基于这个更强的假设，将首先使用$1\times 1$卷积来映射跨通道的相关性，然后将单独映射每个输出通道的空间相关性。如图4所示。我们注意到，Inception模块的这种极端形式几乎等同于一种深度可分离卷积，这种运算早在2014年就被用于神经网络设计，自2016年被纳入TensorFlow框架以来变得越来越流行。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-09-02-Xception--利用深度可分离卷积的深度学习/figure4.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图4. 我们的Inception模块的一个“极端”版本，每个1X1卷积输出通道有一个空间卷积</div>
</center>

&emsp;在诸如TensorFlow和Keras这样的深度学习框架中，一种深度可分离卷积，通常称为“可分离卷积”，首先包含深度卷积，即在输入的每个通道上独立执行的空间卷积，然后是逐点卷积，即$1\times 1$卷积，将深度卷积输出的通道投影到新的通道空间。与空间可分离卷积是不可混淆的，在图像处理领域，空间可分离卷积也被称为“可分离卷积”。

&emsp;Inception模块的“极端”版本和深度可分离卷积之间的两个微小区别是：

* <font color=red>操作顺序</font>：通常实现的深度可分离卷积（例如在TensorFlow中）首先执行通道方向的空间卷积，然后执行$1\times 1$卷积，而Inception首先执行$1\times 1$卷积。

* 在第一次操作后是否存在<font color=red>非线性</font>。在Inception中，这两种操作都有一个ReLU非线性（激活函数），但是深度可分离卷积通常是在没有非线性（激活函数）的情况下实现的。

&emsp;我们认为第一个区别并不重要，特别是因为这些操作是用于堆栈设置的。第二个差异可能很重要，我们将在实验部分对此进行研究（请参见图10）。

&emsp;我们还注意到，位于常规Inception模块和深度可分离卷积之间的Inception模块的其他中间构造也是可能的：实际上，在常规卷积和深度可分离卷积之间存在离散序列，通过用于执行空间卷积的独立通道空间段的数量来参数化。在这个序列的一个极端，一个常规卷积（前面是1x1卷积）对应于单段情况；深度可分离卷积对应于另一个极端，即每个通道有一个段；Inception模块位于两者之间，将数百个通道分成3或4段。这些中间模块的性质似乎还没有被研究过。

&emsp;通过这些观察，我们建议可以通过用深度可分离卷积替换Inception模块来改进Inception体系结构家族，也就是说，通过构建模型，这些模型将是深度可分离卷积的堆栈。这是通过TensorFlow中有效的深度卷积实现来实现的。在接下来的工作中，我们提出了一个基于这一思想的卷积神经网络架构，其参数数目与Inception V3相似，并在两个大规模的图像分类任务上与Inception V3进行性能比较。

## 2. 之前的工作

&emsp;目前的工作在很大程度上依赖于下列领域的先前努力：

* 卷积神经网络，特别是VGG-16体系结构，在一些方面与我们提出的体系结构在图式上相似。

* 卷积神经网络的Inception架构家族，该家族首先展示了将卷积分解为多个分支的优点，这些分支依次在通道上和空间上运行。

* 深度可分离卷积，我们提出的架构完全基于此。虽然在神经网络中使用空间可分离卷积已有很长的历史，至少可以追溯到2012年（但可能更早），但深度版本是最近的。Laurent Sifre于2013年在谷歌Brain实习期间开发了深度可分离卷积，在AlexNet中使用，获得了较小的精度提升和较大的收敛速度提升，模型尺寸显著减小。在ICLR 2014年大会上，他的工作概述首次被公开。详细的实验结果在Sifre的论文6.2中有报道。这项关于深度可分离卷积的初步工作受到了Sifre和Mallat之前关于变换不变散射的研究的启发。后来，用深度可分离卷积作为Inception V1和Inception V2的第一层。在谷歌中，Andrew Howard引入了使用深度可分离卷积的高效移动模型MobileNets。Jin等人在2014年的[Flattened convolutional neural networks for feedforward acceleration]和Wang等人在2016年的[Factorized convolutional neural networks]也做了相关工作，目的是利用可分离卷积降低卷积神经网络的规模和计算成本。此外，我们的工作之所以能够实现，是因为在TensorFlow框架中包含了深度可分离卷积的有效实现。

* 残差连接，由He等人在[Deep residual learning for image recognition]中引入，我们提出的体系结构广泛使用了残差连接。

## 3. Xception架构

&emsp;提出了一种完全基于深度可分离卷积层的卷积神经网络结构。实际上，我们做了如下假设：卷积神经网络特征图中的跨通道相关性和空间相关性可以完全解耦。因为这个假设是在Inception架构下的假设的一个更强的版本，所以我们将我们提出的架构命名为Xception，它代表“极端的Inception”。

&emsp;图5给出了网络规范的完整描述。Xception体系结构由36个卷积层构成网络的特征提取基础。在我们的实验评估中，我们将专门研究图像分类，因此我们的卷积基后面将有一个逻辑回归层。或者，可以在逻辑回归层之前插入完全连接的层，这在实验评估部分进行了探讨（特别是，参见图7和图8）。36个卷积层被构造成14个模块，除第一个和最后一个模块外，所有模块周围都有线性残差连接。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-09-02-Xception--利用深度可分离卷积的深度学习/figure5.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图5. Xception结构：数据首先通过Entry flow，然后通过重复8次的Middle flow，最后通过Exit flow。请注意，所有卷积和可分离卷积层后面都跟着批归一化（图中未包含）。所有可分离卷积层使用1的深度乘数（无深度扩展）。</div>
</center>

&emsp;简而言之，Inception体系结构是一个具有残差连接的深度可分离卷积层的线性堆栈。这使得架构非常容易定义和修改；使用诸如keras或tensorflow slim之类的高级库只需要30到40行代码，这与诸如VGG-16之类的体系结构没有什么不同，而与诸如Inception V2或V3之类的体系结构不同，后者定义起来要复杂得多。一个使用Keras和TensorFlow的Xception开源实现是作为Keras应用程序模块的一部分在MIT许可下提供的（<https://keras.io/applications/#xception>）。

## 4. 实验评估

&emsp;我们选择将Xception与Inception V3体系结构进行比较，因为它们的规模相似：Xception与Inception V3具有几乎相同数量的参数（表3），因此任何性能差异都不能归因于网络容量的差异。我们对两个图像分类任务进行了比较：一个是ImageNet数据集上著名的1000级单标签分类任务，另一个是大型JFT数据集上的17000级多标签分类任务。

### 4.1 JFT数据集

&emsp;JFT是一个用于大型图像分类数据集的内部谷歌数据集，最早由Hinton等人在[Distilling the knowledge in a neural network]中引入，包含超过3.5亿张高分辨率的图像，这些图像使用17000个类的标签进行标注。为了评估基于JFT的模型的性能，我们使用了一个辅助数据集**FastEval14k**。

&emsp;FastEval14k是一个包含14000张图像的数据集，包含大约6000个类的密集注释（平均每个图像有36.5个标签）。在这个数据集中，我们使用前100预测的Mean Average Precision（MAP@100）来评估性能，并用一个分数评估类在社交媒体图像中有多常见（因此也很重要）来对每个类对MAP@100的贡献进行加权。这个评估过程旨在从社交媒体上获取频繁出现的标签的性能，这对谷歌的生产模型至关重要。

### 4.2 优化配置

## 5. 结论

&emsp;我们建议网络架构设计应考虑速度等直接指标，而不是FLOPs等间接指标。我们提出了实用的指导方针和一个新的架构，ShuffleNet V2。综合实验验证了该模型的有效性。我们希望这项工作能够启发未来的网络架构设计工作，使其更具有平台意识和实用性。

## 附录

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-08-26-ShuffleNet V2--高效CNN架构设计的实用指南/a-figure1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">附录图1. 实验中准则3用到的构建块。(a) 1-fragment. (b) 2-fragment-series. (c) 4-fragment-series. (d) 2-fragment-parallel. (e) 4-ragment-parallel.</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-08-26-ShuffleNet V2--高效CNN架构设计的实用指南/a-figure2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">附录图2. 含有SE/残差的ShuffleNet v2构建块。(a)带有残差的ShuffleNet V2。(b)带有SE的ShuffleNet V2。(c)含有SE和残差的ShuffleNet V2。</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-08-26-ShuffleNet V2--高效CNN架构设计的实用指南/a-table1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">附录表1. 表(a)比较了每个网络(整个体系结构)的速度。表(b)比较了每个网络单元的速度，我们将每个网络的10个网络单元堆叠起来；c的值表示ShuffleNet V2的通道数，我们调整通道数以保持其他网络单元的FLOPs不变。详情请参阅第4节。[∗]对于输入大小为320×320的40M FLOPs模型，为了保证GPU的利用率，将batchsize设置为8，否则我们将batchsize设置为1。</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-08-26-ShuffleNet V2--高效CNN架构设计的实用指南/a-table2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">附录表2. 大型模型的架构。构建基块的卷积核形状和堆叠块数显示在括号中。降采样由conv3_1、conv4_1和conv5_1执行，步长为2。对于ShuffleNet V1-50和ResNet-50，瓶颈比率设置为1:4。对于SE-ShuffleNet V2-164，我们在残差add-ReLUs之前添加SE模块（详情见附录图2）；我们将SE模块中的神经元数设置为相应构建块中通道数的1/2。详见第4节。</div>
</center>

---

## 个人看法

&emsp;这篇文章是ShuffleNet的升级版，最主要的贡献是提出了FLOPs其实不足以衡量网络的速度，包括MAC和并行度等因素也需要加以考虑，然后据此提出了构建轻量级网络的四个准则，并根据四个准则，将ShuffleNet中不符合的部分进行修正，从而得到了ShuffleNetV2。

&emsp;再回过头看四个准则，准则1告诉我们输入和输出通道数一致的时候MAC最小，准则2告诉我们减少分组卷积可以减小MAC，准则3告诉我们模型中的分支数越少则模型的并行度越高从而速度越快，准则4告诉我们减少element-wise操作可以加快速度。根据四个准则，再看图3所示的构建块。对比(a)和(c)，可以看到，(c)在一开始的地方有一个channel split的操作以将$c$个输入通道给拆分成$c-c'$和$c'$个通道分别进入两条支路，文章中采用$c'=c/2$，使得最后的输入通道数与输出通道数相等，符合了准则1。而且(c)中也将1×1卷积层中的group操作去掉了符合准则2，其实前面的channel split操作可以看作是一种group操作。(c)里channel shuffle的操作也移到了concat后面，因为前面已经将1×1卷积层中的group操作去掉了，所以也不用在其后添加channel shuffle操作，同时这么做也减少了支路长度，符合准则3。而将element-wise的add操作替换成concat，则符合准则4。最后因为在构建网络的时候会将(c)重复堆叠，所以channel split、concat和channel shuffle这几个操作是可以合并在一起的。
