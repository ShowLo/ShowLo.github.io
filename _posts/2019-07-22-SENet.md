---
layout:     post
title:      SENet
subtitle:   Squeeze-and-Excitation Networks
date:       2019-07-22
author:     CJR
header-img: img/2019-07-22-SENet/post-bg.jpg
catalog: true
mathjax: true
tags:
    - SENet
    - Image Classificatin
    - Lightweight Network
---

# SENet
这篇文章“Squeeze-and-Excitation Networks”是CVPR2018的一篇论文，因为最近看的MnasNet的论文里面提到了SENet里面提出的一个很有用的block，所以又翻出来看了下这篇文章，原论文见 [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507)。

&emsp;下面是对论文的一个简单翻译：

---

## 摘要
&emsp;卷积神经网络（CNN）的核心组成部分是卷积算子，它通过在每一层的局部感受野内融合空间和通道信息，使网络能够构建信息特征。有很多以前的研究已经调查了这一关系的空间组成部分，寻求通过提高整个特征层次的空间编码质量来加强CNN的表征能力。在这项工作中，我们将重点放在通道关系上，并提出了一个新的架构单元，我们称之为“挤压和激励”（SE）块，它通过明确建模通道之间的相互依赖性来自适应地重新校准通道特征响应。我们表明，这些块可以堆叠在一起，形成SENET架构，可以跨不同数据集非常有效地进行泛化。我们进一步证明，SE块为现有最先进的CNN带来了显著的性能改进，而只需稍微增加计算成本。SENet是我们ILVRC 2017分类比赛提交的基础网络，它赢得了第一位，并将top-5错误率降低到了2.251%，超过了2016的获胜网络，相对提高了25%。模型和代码可从<https://github.com/hujie-frank/senet>获得。

## 1. 介绍
&emsp;卷积神经网络（CNN）已经被证明是解决各种视觉任务的有用模型。在网络的每个卷积层上，一组滤波器沿着输入通道表达邻域空间连接模式——在局部感受野内融合空间信息和通道信息。通过将一系列卷积层与非线性激活函数和下采样算子交叉，CNN能够生成图像表征，捕捉层次模式并获得全局理论感受野。计算机视觉研究的一个中心主题是寻找更强大的表示方法，只捕捉图像中对给定任务最显著的属性，从而提高性能。作为一种广泛应用于视觉任务的模型家族，新的神经网络体系结构设计的发展代表了这一研究的一个关键前沿。最近的研究表明，通过将学习机制集成到网络中，帮助捕获特征之间的空间相关性，可以增强CNNs产生的表征。其中一种方法是由Inception系列架构流行起来的，它将多尺度的过程合并到网络模块中，以提高性能。进一步的工作是寻求更好地对空间依赖关系进行建模，并将空间注意力纳入网络结构中。

&emsp;在本文中，我们研究了网络设计的另一个方面——通道之间的关系。我们引入了一个新的体系结构单元，我们称之为挤压-激励(SE)块，其目标是通过显式地建模卷积特征的通道之间相互依赖关系来提高网络产生的表征质量。为此，我们提出一种机制，允许网络执行特征重校准，通过该机制，它可以学习使用全局信息，选择性地强调信息特征，并抑制不太有用的特征。

&emsp;SE构建块的结构如图1所示。对于任意给定的变换$F_{tr}$（例如卷积）将输入$X$映射到特征图$U$，其中$U\in \mathbb{R}^{H\times W\times C}$，我们可以构造一个对应的SE块来进行特征重校准。特征$U$首先通过挤压（Squeeze）操作传递，该操作通过在空间维度($H\times W$)上聚合特征图来生成通道描述符。该描述符的功能是生成一个嵌入通道特征响应的全局分布，允许来自网络的全局感受野的信息被它的所有层使用。挤压之后是激励（excitation）操作，该操作采用简单的自选门机制的形式，以嵌入作为输入，并产生每个通道调制权值的集合。这些权值被应用到特征图$U$中，生成SE块的输出，可以直接输入到网络的后续层中。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-07-22-SENet/figure1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图1. SE块</div>
</center>

&emsp;设计和开发新的CNN架构是一项困难的工程任务，通常需要选择许多新的超参数和层配置。相反，SE块的结构很简单，可以直接在现有的最先进的体系结构中使用，用SE组件替换组件，从而有效地提高性能。SE块在计算上也是轻量级的，只会稍微增加模型的复杂性和计算负担。

&emsp;为了给这些主张提供证据，我们开发了几个SENets，并在ImageNet数据集上进行了广泛的评估。我们还提供了ImageNet之外的结果，这些结果表明我们的方法的好处并不局限于特定的数据集或任务。利用SENets，我们在ILSVRC 2017年分类竞赛中排名第一。我们的最佳模型集成在测试集上获得了2.251%的top-5误差。与前一年的最佳模型（top-5误差为2.991%）相比，这大约有25%的相对改进。

## 2. 相关工作
&emsp;**更深层次的体系结构**。VGGNets和Inception模型表明，增加网络的深度可以显著提高它能够学习的表征质量。通过调节各层输入的分布，批归一化(BN)为深度网络的学习过程增加了稳定性，并产生了更平滑的优化曲面。在这些工作的基础上，ResNets证明，通过使用基于恒等映射的跳层连接，可以学习更深、更强大的网络。Highway Networks引入了一种门控机制以调节沿捷径连接的信息流。在这些工作之后，对网络层之间的连接进行了进一步的重新定义，这显示了对深层网络的学习和表征特性的有希望的改进。

&emsp;另一种与此密切相关的研究方向是改进网络中包含的计算元素的功能形式的方法。 分组卷积已被证明是一种流行的方法，用于增加学习转换的基数。多分支卷积可以实现更灵活的算子组合，可以看作是分组算子的自然扩展。在以往的工作中，通常将跨通道相关性映射为特征的新组合，或者独立于空间结构，或者使用1×1卷积的标准卷积滤波器联合映射。这方面的研究主要集中在减少模型和计算复杂性的目标上，反映了一种假设，即可以将通道关系表示为具有局部感受野的实例不可知函数的组合。相反，我们提出，为单元提供使用全局信息显式地建模通道之间动态、非线性依赖关系的机制可以简化学习过程，并显著增强网络的表示能力。

&emsp;**算法架构搜索**。除了上述工作，还有一个丰富的研究历史，旨在放弃手工架构设计，转而寻求自动学习网络的结构。该领域的早期工作大多是在神经进化社区中进行的，该社区建立了使用进化方法搜索网络拓扑的方法。进化搜索虽然常常需要大量计算，但已经取得了显著的成功，包括为序列模型找到良好的记忆单元，以及为大规模图像分类学习复杂的体系结构。为了减少这些方法的计算量，提出了基于Lamarckian继承和可微体系结构搜索的高效替代方法。

&emsp;通过将架构搜索定义为超参数优化问题，随机搜索和其他更复杂的基于模型的优化技术也可以用来解决这个问题。拓扑选择作为可能的设计结构和直接体系结构预测的一条路径，已经被提出作为额外的可行的架构搜索工具。强化学习技术取得了特别显著的成果。SE块可以作为这些搜索算法的原子构建块，并在并行工作[MnasNet]中被证明是非常有效的。

&emsp;**注意力和门控机制**。注意力可以解释为将可用的计算资源分配给信号中信息量最大的部分的一种方法。注意力机制已经在许多任务中证明了它们的效用，包括序列学习、图像中的定位和理解、图像字幕和唇读。在这些应用中，它可以作为一个操作符合并到一个或多个表示更高级别抽象的层下面，以适应各种模式。一些工作提供了有趣的研究，结合使用空间和通道注意力。Wang等人提出了一种强大的基于沙漏模块的trunk-and-mask注意机制，该机制插入到深度残差网络的中间阶段。相比之下，我们提出的SE块包含一个轻量级的门控机制，其通过以计算高效的方式建模通道关系来增强网络的表征能力。

## 3. SE块

&emsp;SE块是一个计算单元，可以建立在将输入$X\in\mathbb{R}^{H'\times W'\times C'}$映射到特征图$U\in\mathbb{R}^{H\times W\times C}$的变换$F_{tr}$上。在接下来的符号中，我们把$F_{tr}$看作卷积运算符，并使用$V=[v_{1},v_{2},\ldots,v_{C}]$表示所学习的滤波核集，其中$v_{c}$表示第c个滤波器的参数。然后我们可以写出输出$U=[u_{1},u_{2},\ldots,u_{C}]$，其中

$$u_{c}=V_{C}*X=\sum_{s=1}^{C'}v_{c}^{s}*x^{s}$$

&emsp;这里$*$代表卷积，$v_{c}=[v_{c}^{1},v_{c}^{2},\ldots,v_{c}^{C'}]$，$X=[x^{1},x^{2},\ldots,x^{C'}]$且$u_{c}\in\mathbb{R}^{H}\times W$。$v_{c}^{s}$是一个二维空间核，表示$v_{c}$的一个单通道，作用于$X$对应的通道上。为了简化符号，省略了偏置项。由于输出是通过对所有通道的求和产生的，所以通道依赖关系隐式地嵌入到$v_{c}$中，但是与过滤器捕获的局部空间相关性纠缠在一起。卷积建模的通道关系本质上是隐式的和局部的（除了最顶层的那些）。我们期望通过显式地对通道相互依赖关系建模来增强对卷积特性的学习，从而使网络能够提高其对信息特性的敏感性，这些信息特性可以通过后续的转换加以利用。因此，我们希望为它提供对全局信息的访问，并在它们被送入下一个转换之前分两步重新校准过滤器响应，即挤压和激励。图1为SE块结构示意图。

### 3.1 Squeeze：全局信息嵌入

&emsp;为了解决利用通道依赖性的问题，我们首先在输出特性中考虑每个通道的信号。每个学习滤波器都只有一个局部感受野，因此转换输出$U$的每个单元都不能利用该区域之外的上下文信息。

&emsp;为了解决这个问题，我们建议将全局空间信息压缩到通道描述符中。这是通过使用全局平均池来生成通道级统计数据来实现的。形式上，统计量$z\in\mathbb{R}^{C}$是由$U$通过其空间维$H\times W$进行收缩生成的，使得$z$的第$c$个元素由下式计算得到：

$$ z_{c}=F_{sq}(u_{c})=\frac{1}{H\times W}\sum_{i=1}^{H}\sum_{j=1}^{W}u_{c}(i,j) $$

&emsp;*讨论*。转换的输出$U$可以解释为局部描述符的集合，这些局部描述符的统计信息表示整个图像。利用这些信息在以往的特征工程工作中很普遍。我们选择了最简单的聚合技术，全局池化，注意到这里也可以使用更复杂的策略。

### 3.2 Excitation：自适应再校准

&emsp;为了利用在挤压操作中聚合的信息，我们在此之后进行了第二个操作，其目的是完全捕获通道依赖关系。为了实现这一目标，函数必须满足两个标准：第一，它必须是灵活的（特别是它必须能够学习通道之间的非线性相互作用），第二，它必须学习一种非互斥关系，因为我们希望确保多个通道可以被强调（而不是强制只有一个激活（one-hot））。为了满足这些条件，我们选择使用一个简单的使用sigmoid激活函数的门控机制:

$$
s=F_{ex}(z,W)=\sigma(g(z,W))=\sigma(W_{2}\delta(W_{1}z))
$$


&emsp;其中$\delta$是指ReLU函数，$W_{1}\in\mathbb{R}^{\frac{C}{r}\times C}$且$W_{1}\in\mathbb{R}^{C\times\frac{C}{r}}$。为了限制模型的复杂性并有助于泛化，我们通过在非线性周围形成一个具有两个完全连接层的瓶颈来参数化门控机制，即具有缩减率$r$的维度缩减层（该参数选择在第6.1节中讨论）、ReLU和一个维数增加层返回到变换输出$U$的通道维数。块的最终输出是通过使用激活$s$重新缩放$U$获得的：

$$
\tilde{\mathbf{x}}_{c}=\mathbf{F}_{scale}(\mathbf{u}_{c},s_{c})=s_{c}\mathbf{u}_{c}
$$

&emsp;其中$$\tilde{X}=[\tilde{x}_{1},\tilde{x}_{2},\ldots,\tilde{x}_{C}]$$，$$\mathbf{F}_{scale}(\mathbf{u}_{c}, s_{c})$$为标量$s_{c}$与特征图$\mathbf{u}_{c}\in\mathbb{R}^{H\times W}$之间的通道相乘。

&emsp;*讨论*。激励算子将特定于输入的描述符$z$映射到一组通道权值。在这一点上，SE块本质上引入了以输入为条件的动态，它可以被视为通道上的一个自注意函数，这些通道的关系不局限于卷积滤波器响应的局部感受野。

### 3.3 实例化

&emsp;SE块可以通过每次卷积后的非线性插入，集成到VGGNet等标准架构中。此外，SE块的灵活性意味着它可以直接应用于标准卷积之外的转换。为了说明这一点，我们通过将SE块合并到几个更复杂的体系结构示例中来开发SENets，下面将对此进行描述。

&emsp;我们首先考虑Inception网络[5]的SE块的构造。在这里，我们简单地将转换$F_{tr}$作为一个完整的Inception模块（参见图2），通过对体系结构中的每个这样的模块进行此更改，我们获得了一个SE-Inception网络。SE块也可以直接用于残差网络(图3描述了SE- resnet模块的架构)。这里，将SE块变换$F_{tr}$作为残差模块的非恒等分支。挤压和激励都在与恒等分支求和之前发生作用。进一步集成SE块与ResNeXt、Inception-ResNet、MobileNet和ShuffleNet的变体可以通过类似的方案构建。对于SENet体系结构的具体例子，表1给出了SE-ResNet-50和SE-ResNeXt-50的详细描述。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-07-22-SENet/figure2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图2. 原始Inception模块（左）和SE-Inception模块（右）的架构</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-07-22-SENet/figure3.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图3. 原始残差模块（左）和SE-ResNet模块（右）的架构</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-07-22-SENet/table1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">表1. （左）ResNet-50。（中间）SE-ResNet-50。（右）SE-ResNeXt-50，带32×4d模板。括号内列出了残差构建基块的形状和特定参数设置的操作，并给出了一个阶段内的堆叠基块数量。fc后面的内括号表示SE模块中两个完全连接层的输出尺寸。</div>
</center>

&emsp;SE块的灵活性的一个结果是，它可以通过几种可行的方式集成到这些体系结构中。因此，为了评估将SE块纳入网络架构的集成策略的敏感性，我们还在6.5节中提供了消融实验，探索不同的块包含设计。

## 4. 模型与计算复杂度

&emsp;为了使提出的SE块设计具有实际用途，它必须在提高性能和增加模型复杂性之间提供良好的平衡。为了说明与模块相关的计算负担，我们以ResNet-50和SE-ResNet-50之间的比较为例。对于一个224×224像素的输入图像，ResNet-50在一次向前传递中需要约3.86 GFLOPs。每个SE块在挤压阶段使用一个全局平均池化操作，在激励阶段使用两个小的FC层，然后使用一个廉价的通道缩放操作。总的来说，当将缩减率$r$（在第3.2节中介绍）设置为16时，SE-ResNet-50需要约3.87 GFLOPs，相对于原始的ResNet-50增加了0.26%。 作为对这一微小的额外计算负担的交换，SE-ResNet-50的精度超过了ResNet-50，实际上，接近于需要约7.58 GFLOPs的更深层次的ResNet-101网络的精度（表2）。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-07-22-SENet/table2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">表2. ImageNet验证集上的single-crop错误率（%）和复杂性比较。original栏目是指原始论文中报告的结果（ResNets的结果可从以下网站获得：https://github.com/kaiminghe/deep-residual-networks）。为了进行公平的比较，我们对baseline模型进行了重新训练，并在re-implementation列中报告得分。SENet列是指添加了SE块的相应架构。括号中的数字表示对重新实现的baseline的性能改进。$\dagger$表示模型已经在验证集的非黑名单子集上进行了评估（这在[Inception-v4]中进行了更详细的讨论），这可能会略微改善结果。对VGG-16和SE-GG-16用批归一化进行了训练。</div>
</center>

&emsp;在实际操作中，通过ResNet-50进行一次前向和后向的单次传播需要190ms，而使用256张图像的小型训练批处理SE-ResNet-50需要209 ms(这两种计时都是在一台使用8个 NVIDIA Titan X gpu 的服务器上执行的)。我们建议，这代表了一个合理的运行时开销，随着全局池化和小的內积操作在流行的GPU库中得到进一步优化，这可能会进一步减少。由于其对嵌入式设备应用的重要性，我们进一步对每个模型的CPU推理时间进行基准测试：对于224×224像素的输入图像，ResNet-50需要164ms，而SE-ResNet-50需要167ms。我们认为SE块带来的小的额外计算成本是合理的，因为它对模型性能的贡献。

&emsp;接下来，我们将考虑提议的SE块引入的附加参数。这些附加参数仅来自门控机制的两个FC层，因此只占总网络容量的一小部分。具体而言，由各FC层的权值参数引入的总数为：

$$
\frac{2}{r}\sum_{s=1}^{S}N_{s}\cdot C_{s}^{2}
$$

&emsp;$r$表示减速比,$S$是指阶段数（阶段是指在一个共同空间维度的特征图上操作的块集合），$C_{s}$表示输出通道的尺寸，$N_{s}$表示在阶段$s$重复的块的数量（当偏置项用于FC层，引入参数和计算成本通常可以忽略不计）。SE-ResNet-50引入约250万个附加参数，超出了Resnet-50要求的约2500万个参数，相应地增加了约10%。在实践中，这些参数中的大多数来自网络的最后阶段，在这个阶段，激励操作在最大数量的通道上进行。然而，我们发现这种相对昂贵的最后阶段的SE块可以以很小的性能代价（在ImageNet上<0.1%的top-5错误率）进行删除，减少约4%的相对参数增加，这可能在参数使用是关键考虑因素的情况下被证明是有用的（参见6.4节和7.2节的进一步讨论）。

## 5 实验

&emsp;在本节中，我们将进行实验，研究SE块在一系列任务、数据集和模型体系结构中的有效性。

### 5.1 图像分类

&emsp;为了评估SE块的影响，我们首先对ImageNet 2012数据集进行了实验，该数据集包括来自1000个不同类别的128万个训练图像和50K个验证图像。我们在训练集上训练网络，并在验证集上报告top-1和top-5个错误率。

&emsp;每个基线网络体系结构及其对应的SE对等结构都使用相同的优化方案进行训练。我们遵循标准做法，使用scale和纵横比将图片随机裁剪为224×224像素的尺寸（或299×299，用于Inception-ResNet-v2和SE-Inception-ResNet-v2），并执行随机水平翻转，从而实现数据增强。每个输入图像通过平均RGB通道减法归一化。所有的模型都在我们的分布式学习系统ROCS上进行训练，该系统旨在处理大型网络的有效并行训练。优化是使用一个momentum为0.9、小批量大小为1024的同步SGD进行的。初始学习率设置为0.6，每30个epoch降低10倍。使用[Delving deep into rectifiers : Surpassing human-level performance on ImageNet classification]中描述的权重初始化策略，模型从零开始进行100个epoch的训练。缺省情况下，缩减率$r$（在第3.2节中）设置为16（除非另有说明）。

&emsp;在评估模型时，我们应用了中心裁剪，以便从每个图像中裁剪224×224个像素，在其较短的边缘先调整为256之后（从其较短的边缘先调整为352的图像中裁剪299×299，用于Inception-ResNet-v2和SE-Inception-ResNet-v2）。

&emsp;**网络深度**。我们首先将SE-ResNet与不同深度的ResNet体系结构进行比较，并在表2中报告结果。我们观察到SE块在不同深度上持续地提高性能，而计算复杂度的增加非常小。值得注意的是，SE-ResNet-50实现了6.62%的single-crop top-5验证错误率，比ResNet-50（7.48%）高出0.86%，接近更深层的ResNet-101网络（6.52%的top-5错误率）所实现的性能，仅占总计算量的一半（3.87 GFLOPs vs 7.58 GFLOPs）。这种模式在更深的地方重复出现，SE-ResNet-101(top-5错误率6.07%)不仅匹配，而且比更深的ResNet-152网络（top-5错误率6.34%）的性能高出0.27%。虽然应该注意到SE块本身增加了深度，但是它们以一种非常高效的计算方式增加了深度，并且即使在扩展基础架构的深度达到收益递减的程度时，也会产生良好的收益。此外，我们还发现，在不同的网络深度范围内，这些增益是一致的，这表明SE块所带来的改进可能与仅仅通过增加基础架构的深度所获得的改进是互补的。

&emsp;**与新式模型的集成**。接下来，我们将研究将SE块与另外两个最先进的架构Inception-ResNet-v2和ResNeXt（使用32×4d的设置）集成的效果，这两个架构都将额外的计算构建块引入到基本网络中。我们构建了这些网络的SENet等价物SE-Inception-ResNet-v2和SE-ResNeXt（SE-ResNeXt-50的配置如表1所示），并在表2中报告结果。与之前的实验一样，我们观察到在这两种体系结构中引入SE块所带来的显著性能改进。特别是，SE-ResNext-50的top-5错误率为5.49%，优于其直接对应的ResNext-50（5.90%的top-5错误率）和更深的ResNext-101（5.57%的top-5错误率，该模型的参数总数和计算开销几乎是前者的两倍）。我们注意到，在我们重新实现的Inception-ResNet-v2和在[Inception-v4]中报告的结果之间，性能略有不同。然而，我们在SE块的效果上观察到一个类似的趋势，发现SE对应物（4.79%的top-5错误率）比我们重新实现的Inception-ResNet-v2基线（5.21%的top-5错误）的性能好0.42%，同样比在[Inception-v4]中报告的结果好。我们还通过使用VGG-16和BN-Inception架构进行实验，评估了SE块在非残差网络上运行时的效果。为了便于VGG-16的从无到有的训练，我们在每次卷积后都添加了批归一化层。我们对VGG-16和SE-VGG-16使用相同的训练方案。比较结果如表2所示。与报告的残差基线体系结构的结果类似，我们观察到SE块在非残差设置上带来了性能上的改进。

&emsp;为了深入了解SE块对这些模型优化的影响，图4中描述了基线体系结构及其相应SE块运行的示例训练曲线。我们观察到SE块在整个优化过程中产生了稳定的改善。此外，这种趋势在一系列被视为基线的网络体系结构中是相当一致的。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-07-22-SENet/figure4.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图4. 在ImageNet上训练基线体系结构及其SeNet对应项。SENet表现出改进的优化特性，并在整个训练过程中持续不断地提高性能。</div>
</center>

&emsp;**移动设置**。最后，我们考虑了两种典型的移动优化网络架构，MobileNet和ShuffleNet。在这些实验中，我们使用了大小为256的小批数据，并使用了与[ShuffleNet]类似的稍微不那么积极的数据增强和正则化。我们使用SGD（momentum设置为0.9）在8个gpu上对模型进行训练，初始学习率为0.1，每次验证损失趋于稳定时，学习率降低10倍。整个培训过程需要约400个epoch（使我们能够重现[ShuffleNet]的基线性能）。表3中报告的结果表明，SE块以最小的计算成本提高了较大的精度。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-07-22-SENet/table3.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">表3. ImageNet验证集上的single-crop错误率（%）和复杂性比较。mobilenet表示“1.0 mobilenet-224”，shufflenet表示“shufflenet 1×(g=3)”。括号中的数字表示与重实现相比的性能改进。</div>
</center>

&emsp;**额外的数据集**。接下来，我们将研究SE块的好处是否可以推广到ImageNet之外的数据集。我们在CIFAR-10和CIFAR-100数据集上使用几种流行的基线架构和技术（ResNet-110、ResNet-164、WideResNet-16-8、Shake-Shake和Cutout）进行实验。这些包括50k训练和10k测试32×32像素RGB图像的集合，分别标记为10个类和100个类。将SE块集成到这些网络中遵循与第3.3节中描述的相同的方法。每个基线及其SENet对应物都使用标准的数据增强策略进行训练。在训练过程中，随机水平翻转图像，每侧填充4个像素，然后随机进行32×32的裁剪。平均值和标准偏差归一化也被应用。训练超参数的设置(如:小批量大小、初始学习率、重量衰减)与原论文建议的匹配。我们在表4中报告了每个基线及其SENet配对物在CIFAR-10上的性能，在表5中报告了CIFAR-100的性能。我们观察到，在每次比较中，SENets都优于基线架构，这表明SE块的好处并不局限于ImageNet数据集。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-07-22-SENet/table4.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">表4. CIFAR-10上的分类误差（%）</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://raw.githubusercontent.com/ShowLo/ShowLo.github.io/master/img/2019-07-22-SENet/table5.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">表5. CIFAR-100上的分类误差（%）</div>
</center>

### 5.2 场景分类

&emsp;我们还对Places365-Challenge数据集进行了场景分类实验。该数据集包含365个类别的800万张训练图像和36500张验证图像。相对于分类，场景理解的任务提供了另一种评估模型泛化和处理抽象能力的方法。这是因为它通常要求模型处理更复杂的数据关联，并对更大程度的外观变化保持健壮性。

&emsp;我们选择使用ResNet-152作为强基线来评估SE块的有效性，并遵循[Places401 and places365 models]、[Relay backpropagation for effective learning of deep convolutional neural networks]中描述的训练和评估报告。在这些实验中，模型是从零开始训练的。我们在表6中报告了结果，并与之前的工作进行了比较。我们观察到SE-ResNet-152(top-5误差率11.01%）的验证误差低于ResNet-152(top-5误差率11.61%)，提供证据表明SE块也可以改进场景分类。这款SENet超越了之前最先进的模型Places-365-CNN，其在这项任务上的top-5误差率为11.48%。

### 5.3 COCO上的目标检测

&emsp;